{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bobcasta/.churn_env/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 1;\n                var nbb_unformatted_code = \"# Imports\\nimport numpy as np\\nimport pandas as pd\\nimport matplotlib.pyplot as plt\\nfrom category_encoders import CatBoostEncoder\\nfrom sklearn.ensemble import (\\n    RandomForestClassifier,\\n    GradientBoostingClassifier,\\n    HistGradientBoostingClassifier,\\n)\\nfrom lightgbm import LGBMClassifier\\nfrom xgboost import XGBClassifier\\nfrom sklearn.pipeline import Pipeline, make_pipeline\\nfrom sklearn.compose import ColumnTransformer, make_column_selector\\nfrom feature_engine.imputation import DropMissingData\\nfrom feature_engine.selection import DropFeatures\\nfrom feature_engine.creation import CombineWithReferenceFeature\\nfrom sklearn.impute import SimpleImputer\\nfrom category_encoders import TargetEncoder\\nfrom sklearn.model_selection import cross_val_score, RepeatedStratifiedKFold\\nfrom sklearn.metrics import (\\n    classification_report,\\n    f1_score,\\n    precision_recall_curve,\\n    roc_auc_score,\\n    plot_roc_curve,\\n)\\nimport optuna\\nimport warnings\\n\\n# Config\\n%matplotlib inline\\n%load_ext nb_black\\n%load_ext lab_black\\npd.set_option(\\\"display.max_columns\\\", None)\\nwarnings.filterwarnings(\\\"ignore\\\")\";\n                var nbb_formatted_code = \"# Imports\\nimport numpy as np\\nimport pandas as pd\\nimport matplotlib.pyplot as plt\\nfrom category_encoders import CatBoostEncoder\\nfrom sklearn.ensemble import (\\n    RandomForestClassifier,\\n    GradientBoostingClassifier,\\n    HistGradientBoostingClassifier,\\n)\\nfrom lightgbm import LGBMClassifier\\nfrom xgboost import XGBClassifier\\nfrom sklearn.pipeline import Pipeline, make_pipeline\\nfrom sklearn.compose import ColumnTransformer, make_column_selector\\nfrom feature_engine.imputation import DropMissingData\\nfrom feature_engine.selection import DropFeatures\\nfrom feature_engine.creation import CombineWithReferenceFeature\\nfrom sklearn.impute import SimpleImputer\\nfrom category_encoders import TargetEncoder\\nfrom sklearn.model_selection import cross_val_score, RepeatedStratifiedKFold\\nfrom sklearn.metrics import (\\n    classification_report,\\n    f1_score,\\n    precision_recall_curve,\\n    roc_auc_score,\\n    plot_roc_curve,\\n)\\nimport optuna\\nimport warnings\\n\\n# Config\\n%matplotlib inline\\n%load_ext nb_black\\n%load_ext lab_black\\npd.set_option(\\\"display.max_columns\\\", None)\\nwarnings.filterwarnings(\\\"ignore\\\")\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from category_encoders import CatBoostEncoder\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier,\n",
    "    GradientBoostingClassifier,\n",
    "    HistGradientBoostingClassifier,\n",
    ")\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector\n",
    "from feature_engine.imputation import DropMissingData\n",
    "from feature_engine.selection import DropFeatures\n",
    "from feature_engine.creation import CombineWithReferenceFeature\n",
    "from sklearn.impute import SimpleImputer\n",
    "from category_encoders import TargetEncoder\n",
    "from sklearn.model_selection import cross_val_score, RepeatedStratifiedKFold\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    f1_score,\n",
    "    precision_recall_curve,\n",
    "    roc_auc_score,\n",
    "    plot_roc_curve,\n",
    ")\n",
    "import optuna\n",
    "import warnings\n",
    "\n",
    "# Config\n",
    "%matplotlib inline\n",
    "%load_ext nb_black\n",
    "%load_ext lab_black\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 2;\n                var nbb_unformatted_code = \"X_train = pd.read_csv(\\\"../data/raw/train.csv\\\")\\nX_test = pd.read_csv(\\\"../data/raw/test.csv\\\")\";\n                var nbb_formatted_code = \"X_train = pd.read_csv(\\\"../data/raw/train.csv\\\")\\nX_test = pd.read_csv(\\\"../data/raw/test.csv\\\")\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train = pd.read_csv(\"../data/raw/train.csv\")\n",
    "X_test = pd.read_csv(\"../data/raw/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 3;\n                var nbb_unformatted_code = \"X_train[\\\"Churn\\\"] = X_train[\\\"Churn\\\"].map({\\\"Yes\\\": 1, \\\"No\\\": 0})\\nX_test[\\\"Churn\\\"] = X_test[\\\"Churn\\\"].map({\\\"Yes\\\": 1, \\\"No\\\": 0})\";\n                var nbb_formatted_code = \"X_train[\\\"Churn\\\"] = X_train[\\\"Churn\\\"].map({\\\"Yes\\\": 1, \\\"No\\\": 0})\\nX_test[\\\"Churn\\\"] = X_test[\\\"Churn\\\"].map({\\\"Yes\\\": 1, \\\"No\\\": 0})\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train[\"Churn\"] = X_train[\"Churn\"].map({\"Yes\": 1, \"No\": 0})\n",
    "X_test[\"Churn\"] = X_test[\"Churn\"].map({\"Yes\": 1, \"No\": 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 4;\n                var nbb_unformatted_code = \"def casting_numerical(dataframe, numerical_feature):\\n    \\\"\\\"\\\"Cast features to the correct type.\\\"\\\"\\\"\\n    dataframe[numerical_feature] = dataframe[numerical_feature].apply(\\n        lambda dataframe: str(dataframe).replace(\\\",\\\", \\\".\\\"),\\n    )\\n    dataframe[numerical_feature] = pd.to_numeric(\\n        dataframe[numerical_feature], errors=\\\"coerce\\\"\\n    )\\n    dataframe[numerical_feature] = dataframe[numerical_feature].astype(\\\"float64\\\")\\n    dataframe[numerical_feature] = dataframe[numerical_feature].replace(\\\"\\\", np.nan)\\n    return dataframe\\n\\n\\ndef casting_categorical(dataframe, categorical_feature):\\n    \\\"\\\"\\\"Cast features to the correct type.\\\"\\\"\\\"\\n    dataframe[categorical_feature] = dataframe[categorical_feature].astype(\\\"object\\\")\\n    return dataframe\";\n                var nbb_formatted_code = \"def casting_numerical(dataframe, numerical_feature):\\n    \\\"\\\"\\\"Cast features to the correct type.\\\"\\\"\\\"\\n    dataframe[numerical_feature] = dataframe[numerical_feature].apply(\\n        lambda dataframe: str(dataframe).replace(\\\",\\\", \\\".\\\"),\\n    )\\n    dataframe[numerical_feature] = pd.to_numeric(\\n        dataframe[numerical_feature], errors=\\\"coerce\\\"\\n    )\\n    dataframe[numerical_feature] = dataframe[numerical_feature].astype(\\\"float64\\\")\\n    dataframe[numerical_feature] = dataframe[numerical_feature].replace(\\\"\\\", np.nan)\\n    return dataframe\\n\\n\\ndef casting_categorical(dataframe, categorical_feature):\\n    \\\"\\\"\\\"Cast features to the correct type.\\\"\\\"\\\"\\n    dataframe[categorical_feature] = dataframe[categorical_feature].astype(\\\"object\\\")\\n    return dataframe\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def casting_numerical(dataframe, numerical_feature):\n",
    "    \"\"\"Cast features to the correct type.\"\"\"\n",
    "    dataframe[numerical_feature] = dataframe[numerical_feature].apply(\n",
    "        lambda dataframe: str(dataframe).replace(\",\", \".\"),\n",
    "    )\n",
    "    dataframe[numerical_feature] = pd.to_numeric(\n",
    "        dataframe[numerical_feature], errors=\"coerce\"\n",
    "    )\n",
    "    dataframe[numerical_feature] = dataframe[numerical_feature].astype(\"float64\")\n",
    "    dataframe[numerical_feature] = dataframe[numerical_feature].replace(\"\", np.nan)\n",
    "    return dataframe\n",
    "\n",
    "\n",
    "def casting_categorical(dataframe, categorical_feature):\n",
    "    \"\"\"Cast features to the correct type.\"\"\"\n",
    "    dataframe[categorical_feature] = dataframe[categorical_feature].astype(\"object\")\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 5;\n                var nbb_unformatted_code = \"# apply casting_numerical function to X_train and X_test simultaneously\\nX_train, X_test = map(\\n    lambda dataframe: casting_numerical(dataframe, \\\"TotalCharges\\\"),\\n    [X_train, X_test],\\n)\\n\\nX_train, X_test = map(\\n    lambda dataframe: casting_categorical(dataframe, \\\"SeniorCitizen\\\"),\\n    [X_train, X_test],\\n)\";\n                var nbb_formatted_code = \"# apply casting_numerical function to X_train and X_test simultaneously\\nX_train, X_test = map(\\n    lambda dataframe: casting_numerical(dataframe, \\\"TotalCharges\\\"),\\n    [X_train, X_test],\\n)\\n\\nX_train, X_test = map(\\n    lambda dataframe: casting_categorical(dataframe, \\\"SeniorCitizen\\\"),\\n    [X_train, X_test],\\n)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# apply casting_numerical function to X_train and X_test simultaneously\n",
    "X_train, X_test = map(\n",
    "    lambda dataframe: casting_numerical(dataframe, \"TotalCharges\"),\n",
    "    [X_train, X_test],\n",
    ")\n",
    "\n",
    "X_train, X_test = map(\n",
    "    lambda dataframe: casting_categorical(dataframe, \"SeniorCitizen\"),\n",
    "    [X_train, X_test],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 6;\n                var nbb_unformatted_code = \"# dropna from X_train and X_test simultaneously\\nX_train, X_test = map(lambda dataframe: dataframe.dropna(), [X_train, X_test])\";\n                var nbb_formatted_code = \"# dropna from X_train and X_test simultaneously\\nX_train, X_test = map(lambda dataframe: dataframe.dropna(), [X_train, X_test])\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# dropna from X_train and X_test simultaneously\n",
    "X_train, X_test = map(lambda dataframe: dataframe.dropna(), [X_train, X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 7;\n                var nbb_unformatted_code = \"y_train = X_train[\\\"Churn\\\"]\\nX_train = X_train.drop(\\\"Churn\\\", axis=1)\\n\\ny_test = X_test[\\\"Churn\\\"]\\nX_test = X_test.drop(\\\"Churn\\\", axis=1)\";\n                var nbb_formatted_code = \"y_train = X_train[\\\"Churn\\\"]\\nX_train = X_train.drop(\\\"Churn\\\", axis=1)\\n\\ny_test = X_test[\\\"Churn\\\"]\\nX_test = X_test.drop(\\\"Churn\\\", axis=1)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_train = X_train[\"Churn\"]\n",
    "X_train = X_train.drop(\"Churn\", axis=1)\n",
    "\n",
    "y_test = X_test[\"Churn\"]\n",
    "X_test = X_test.drop(\"Churn\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 8;\n                var nbb_unformatted_code = \"def objective(trial):\\n\\n    params = {\\n        \\\"classifier__n_estimators\\\": trial.suggest_int(\\n            \\\"classifier__n_estimators\\\", 100, 1000\\n        ),\\n        \\\"classifier__max_depth\\\": trial.suggest_int(\\\"classifier__max_depth\\\", 3, 10),\\n        \\\"classifier__learning_rate\\\": trial.suggest_loguniform(\\n            \\\"classifier__learning_rate\\\", 1e-3, 1.0\\n        ),\\n        \\\"classifier__subsample\\\": trial.suggest_uniform(\\n            \\\"classifier__subsample\\\", 0.2, 1.0\\n        ),\\n        \\\"classifier__colsample_bytree\\\": trial.suggest_uniform(\\n            \\\"classifier__colsample_bytree\\\", 0.2, 1.0\\n        ),\\n        \\\"classifier__reg_alpha\\\": trial.suggest_loguniform(\\n            \\\"classifier__reg_alpha\\\", 1e-3, 10.0\\n        ),\\n        \\\"classifier__reg_lambda\\\": trial.suggest_loguniform(\\n            \\\"classifier__reg_lambda\\\", 1e-3, 10.0\\n        ),\\n    }\\n\\n    pipeline = Pipeline(\\n        [\\n            (\\\"drop_vars\\\", DropFeatures([\\\"customerID\\\"])),\\n            (\\n                \\\"tenure_combine\\\",\\n                CombineWithReferenceFeature(\\n                    variables_to_combine=[\\\"MonthlyCharges\\\", \\\"TotalCharges\\\"],\\n                    reference_variables=[\\\"tenure\\\"],\\n                    operations=[\\\"div\\\"],\\n                    new_variables_names=[\\\"tenureMonthlyRate\\\", \\\"tenureTotalRate\\\"],\\n                ),\\n            ),\\n            (\\n                \\\"totalcharges_combine\\\",\\n                CombineWithReferenceFeature(\\n                    variables_to_combine=[\\\"TotalCharges\\\"],\\n                    reference_variables=[\\\"MonthlyCharges\\\"],\\n                    operations=[\\\"div\\\"],\\n                    new_variables_names=[\\\"RateCharge\\\"],\\n                ),\\n            ),\\n            (\\n                \\\"preprocessor\\\",\\n                ColumnTransformer(\\n                    [\\n                        (\\n                            \\\"num\\\",\\n                            make_pipeline(\\n                                SimpleImputer(strategy=\\\"median\\\"),\\n                            ),\\n                            make_column_selector(dtype_include=np.number),\\n                        ),\\n                        (\\n                            \\\"cat\\\",\\n                            make_pipeline(\\n                                SimpleImputer(strategy=\\\"most_frequent\\\"),\\n                                TargetEncoder(),\\n                            ),\\n                            make_column_selector(dtype_include=[\\\"object\\\"]),\\n                        ),\\n                    ]\\n                ),\\n            ),\\n            (\\\"classifier\\\", XGBClassifier(**params, random_state=42)),\\n        ]\\n    )\\n\\n    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=42)\\n\\n    scores = cross_val_score(pipeline, X_train, y_train, cv=cv, scoring=\\\"f1\\\")\\n\\n    return scores.mean()\";\n                var nbb_formatted_code = \"def objective(trial):\\n\\n    params = {\\n        \\\"classifier__n_estimators\\\": trial.suggest_int(\\n            \\\"classifier__n_estimators\\\", 100, 1000\\n        ),\\n        \\\"classifier__max_depth\\\": trial.suggest_int(\\\"classifier__max_depth\\\", 3, 10),\\n        \\\"classifier__learning_rate\\\": trial.suggest_loguniform(\\n            \\\"classifier__learning_rate\\\", 1e-3, 1.0\\n        ),\\n        \\\"classifier__subsample\\\": trial.suggest_uniform(\\n            \\\"classifier__subsample\\\", 0.2, 1.0\\n        ),\\n        \\\"classifier__colsample_bytree\\\": trial.suggest_uniform(\\n            \\\"classifier__colsample_bytree\\\", 0.2, 1.0\\n        ),\\n        \\\"classifier__reg_alpha\\\": trial.suggest_loguniform(\\n            \\\"classifier__reg_alpha\\\", 1e-3, 10.0\\n        ),\\n        \\\"classifier__reg_lambda\\\": trial.suggest_loguniform(\\n            \\\"classifier__reg_lambda\\\", 1e-3, 10.0\\n        ),\\n    }\\n\\n    pipeline = Pipeline(\\n        [\\n            (\\\"drop_vars\\\", DropFeatures([\\\"customerID\\\"])),\\n            (\\n                \\\"tenure_combine\\\",\\n                CombineWithReferenceFeature(\\n                    variables_to_combine=[\\\"MonthlyCharges\\\", \\\"TotalCharges\\\"],\\n                    reference_variables=[\\\"tenure\\\"],\\n                    operations=[\\\"div\\\"],\\n                    new_variables_names=[\\\"tenureMonthlyRate\\\", \\\"tenureTotalRate\\\"],\\n                ),\\n            ),\\n            (\\n                \\\"totalcharges_combine\\\",\\n                CombineWithReferenceFeature(\\n                    variables_to_combine=[\\\"TotalCharges\\\"],\\n                    reference_variables=[\\\"MonthlyCharges\\\"],\\n                    operations=[\\\"div\\\"],\\n                    new_variables_names=[\\\"RateCharge\\\"],\\n                ),\\n            ),\\n            (\\n                \\\"preprocessor\\\",\\n                ColumnTransformer(\\n                    [\\n                        (\\n                            \\\"num\\\",\\n                            make_pipeline(\\n                                SimpleImputer(strategy=\\\"median\\\"),\\n                            ),\\n                            make_column_selector(dtype_include=np.number),\\n                        ),\\n                        (\\n                            \\\"cat\\\",\\n                            make_pipeline(\\n                                SimpleImputer(strategy=\\\"most_frequent\\\"),\\n                                TargetEncoder(),\\n                            ),\\n                            make_column_selector(dtype_include=[\\\"object\\\"]),\\n                        ),\\n                    ]\\n                ),\\n            ),\\n            (\\\"classifier\\\", XGBClassifier(**params, random_state=42)),\\n        ]\\n    )\\n\\n    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=42)\\n\\n    scores = cross_val_score(pipeline, X_train, y_train, cv=cv, scoring=\\\"f1\\\")\\n\\n    return scores.mean()\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def objective(trial):\n",
    "\n",
    "    params = {\n",
    "        \"classifier__n_estimators\": trial.suggest_int(\n",
    "            \"classifier__n_estimators\", 100, 1000\n",
    "        ),\n",
    "        \"classifier__max_depth\": trial.suggest_int(\"classifier__max_depth\", 3, 10),\n",
    "        \"classifier__learning_rate\": trial.suggest_loguniform(\n",
    "            \"classifier__learning_rate\", 1e-3, 1.0\n",
    "        ),\n",
    "        \"classifier__subsample\": trial.suggest_uniform(\n",
    "            \"classifier__subsample\", 0.2, 1.0\n",
    "        ),\n",
    "        \"classifier__colsample_bytree\": trial.suggest_uniform(\n",
    "            \"classifier__colsample_bytree\", 0.2, 1.0\n",
    "        ),\n",
    "        \"classifier__reg_alpha\": trial.suggest_loguniform(\n",
    "            \"classifier__reg_alpha\", 1e-3, 10.0\n",
    "        ),\n",
    "        \"classifier__reg_lambda\": trial.suggest_loguniform(\n",
    "            \"classifier__reg_lambda\", 1e-3, 10.0\n",
    "        ),\n",
    "    }\n",
    "\n",
    "    pipeline = Pipeline(\n",
    "        [\n",
    "            (\"drop_vars\", DropFeatures([\"customerID\"])),\n",
    "            (\n",
    "                \"tenure_combine\",\n",
    "                CombineWithReferenceFeature(\n",
    "                    variables_to_combine=[\"MonthlyCharges\", \"TotalCharges\"],\n",
    "                    reference_variables=[\"tenure\"],\n",
    "                    operations=[\"div\"],\n",
    "                    new_variables_names=[\"tenureMonthlyRate\", \"tenureTotalRate\"],\n",
    "                ),\n",
    "            ),\n",
    "            (\n",
    "                \"totalcharges_combine\",\n",
    "                CombineWithReferenceFeature(\n",
    "                    variables_to_combine=[\"TotalCharges\"],\n",
    "                    reference_variables=[\"MonthlyCharges\"],\n",
    "                    operations=[\"div\"],\n",
    "                    new_variables_names=[\"RateCharge\"],\n",
    "                ),\n",
    "            ),\n",
    "            (\n",
    "                \"preprocessor\",\n",
    "                ColumnTransformer(\n",
    "                    [\n",
    "                        (\n",
    "                            \"num\",\n",
    "                            make_pipeline(\n",
    "                                SimpleImputer(strategy=\"median\"),\n",
    "                            ),\n",
    "                            make_column_selector(dtype_include=np.number),\n",
    "                        ),\n",
    "                        (\n",
    "                            \"cat\",\n",
    "                            make_pipeline(\n",
    "                                SimpleImputer(strategy=\"most_frequent\"),\n",
    "                                TargetEncoder(),\n",
    "                            ),\n",
    "                            make_column_selector(dtype_include=[\"object\"]),\n",
    "                        ),\n",
    "                    ]\n",
    "                ),\n",
    "            ),\n",
    "            (\"classifier\", XGBClassifier(**params, random_state=42)),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=42)\n",
    "\n",
    "    scores = cross_val_score(pipeline, X_train, y_train, cv=cv, scoring=\"f1\")\n",
    "\n",
    "    return scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "study = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    "    study_name=\"xgb\",\n",
    ")\n",
    "study.optimize(objective, n_trials=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imprime os resultados da otimização\n",
    "print(\"The Bests Parameters are: \", study.best_params)\n",
    "print(\"The Best Score Value is: \", study.best_value)\n",
    "print(\"The Best Trial is: \", study.best_trial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# use the best parameters to fit the model\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"drop_vars\", DropFeatures([\"customerID\"])),\n",
    "        (\n",
    "            \"tenure_combine\",\n",
    "            CombineWithReferenceFeature(\n",
    "                variables_to_combine=[\"MonthlyCharges\", \"TotalCharges\"],\n",
    "                reference_variables=[\"tenure\"],\n",
    "                operations=[\"div\"],\n",
    "                new_variables_names=[\"tenureMonthlyRate\", \"tenureTotalRate\"],\n",
    "            ),\n",
    "        ),\n",
    "        (\n",
    "            \"totalcharges_combine\",\n",
    "            CombineWithReferenceFeature(\n",
    "                variables_to_combine=[\"TotalCharges\"],\n",
    "                reference_variables=[\"MonthlyCharges\"],\n",
    "                operations=[\"div\"],\n",
    "                new_variables_names=[\"RateCharge\"],\n",
    "            ),\n",
    "        ),\n",
    "        (\n",
    "            \"preprocessor\",\n",
    "            ColumnTransformer(\n",
    "                [\n",
    "                    (\n",
    "                        \"num\",\n",
    "                        make_pipeline(\n",
    "                            SimpleImputer(strategy=\"median\"),\n",
    "                        ),\n",
    "                        make_column_selector(dtype_include=np.number),\n",
    "                    ),\n",
    "                    (\n",
    "                        \"cat\",\n",
    "                        make_pipeline(\n",
    "                            SimpleImputer(strategy=\"most_frequent\"),\n",
    "                            TargetEncoder(),\n",
    "                        ),\n",
    "                        make_column_selector(dtype_include=[\"object\"]),\n",
    "                    ),\n",
    "                ]\n",
    "            ),\n",
    "        ),\n",
    "        (\n",
    "            \"classifier\",\n",
    "            XGBClassifier(\n",
    "                **study.best_params,\n",
    "                random_state=42,\n",
    "            ),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('.churn_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "33756bd410fd1575cb7e1e8676668def99b13921af9d80f486eabc1b4c62c886"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
