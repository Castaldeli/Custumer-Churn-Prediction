{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bobcasta/.churnenv/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 1;\n                var nbb_unformatted_code = \"import numpy as np\\nimport pandas as pd\\nimport matplotlib.pyplot as plt\\nimport seaborn as sns\\nimport plotly.express as px\\nimport plotly.graph_objects as go\\nfrom sklearn.ensemble import GradientBoostingClassifier\\nfrom sklearn.pipeline import Pipeline, make_pipeline\\nfrom sklearn.compose import ColumnTransformer, make_column_selector\\nfrom feature_engine.selection import DropFeatures\\nfrom feature_engine.creation import CombineWithReferenceFeature\\nfrom sklearn.impute import SimpleImputer\\nfrom category_encoders import TargetEncoder\\nfrom sklearn.model_selection import (\\n    cross_val_score,\\n    RepeatedStratifiedKFold,\\n    learning_curve,\\n)\\nfrom sklearn.metrics import (\\n    classification_report,\\n    f1_score,\\n    precision_recall_curve,\\n    roc_auc_score,\\n    plot_roc_curve,\\n)\\nimport optuna\\nimport warnings\\n\\n\\n# Config\\n%matplotlib inline\\n%load_ext nb_black\\n%load_ext lab_black\\npd.set_option(\\\"display.max_columns\\\", None)\\nwarnings.filterwarnings(\\\"ignore\\\", category=FutureWarning)\\nwarnings.simplefilter(action=\\\"ignore\\\", category=FutureWarning)\";\n                var nbb_formatted_code = \"import numpy as np\\nimport pandas as pd\\nimport matplotlib.pyplot as plt\\nimport seaborn as sns\\nimport plotly.express as px\\nimport plotly.graph_objects as go\\nfrom sklearn.ensemble import GradientBoostingClassifier\\nfrom sklearn.pipeline import Pipeline, make_pipeline\\nfrom sklearn.compose import ColumnTransformer, make_column_selector\\nfrom feature_engine.selection import DropFeatures\\nfrom feature_engine.creation import CombineWithReferenceFeature\\nfrom sklearn.impute import SimpleImputer\\nfrom category_encoders import TargetEncoder\\nfrom sklearn.model_selection import (\\n    cross_val_score,\\n    RepeatedStratifiedKFold,\\n    learning_curve,\\n)\\nfrom sklearn.metrics import (\\n    classification_report,\\n    f1_score,\\n    precision_recall_curve,\\n    roc_auc_score,\\n    plot_roc_curve,\\n)\\nimport optuna\\nimport warnings\\n\\n\\n# Config\\n%matplotlib inline\\n%load_ext nb_black\\n%load_ext lab_black\\npd.set_option(\\\"display.max_columns\\\", None)\\nwarnings.filterwarnings(\\\"ignore\\\", category=FutureWarning)\\nwarnings.simplefilter(action=\\\"ignore\\\", category=FutureWarning)\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector\n",
    "from feature_engine.selection import DropFeatures\n",
    "from feature_engine.creation import CombineWithReferenceFeature\n",
    "from sklearn.impute import SimpleImputer\n",
    "from category_encoders import TargetEncoder\n",
    "from sklearn.model_selection import (\n",
    "    cross_val_score,\n",
    "    RepeatedStratifiedKFold,\n",
    "    learning_curve,\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    f1_score,\n",
    "    precision_recall_curve,\n",
    "    roc_auc_score,\n",
    "    plot_roc_curve,\n",
    ")\n",
    "import optuna\n",
    "import warnings\n",
    "\n",
    "\n",
    "# Config\n",
    "%matplotlib inline\n",
    "%load_ext nb_black\n",
    "%load_ext lab_black\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "X_train = pd.read_csv(\"../data/raw/train.csv\")\n",
    "X_test = pd.read_csv(\"../data/raw/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "X_train[\"Churn\"] = X_train[\"Churn\"].map({\"Yes\": 1, \"No\": 0})\n",
    "X_test[\"Churn\"] = X_test[\"Churn\"].map({\"Yes\": 1, \"No\": 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def casting_numerical(dataframe, numerical_feature):\n",
    "    \"\"\"Cast features to the correct type.\"\"\"\n",
    "    dataframe[numerical_feature] = dataframe[numerical_feature].apply(\n",
    "        lambda dataframe: str(dataframe).replace(\",\", \".\"),\n",
    "    )\n",
    "    dataframe[numerical_feature] = pd.to_numeric(\n",
    "        dataframe[numerical_feature], errors=\"coerce\"\n",
    "    )\n",
    "    dataframe[numerical_feature] = dataframe[numerical_feature].astype(\"float64\")\n",
    "    dataframe[numerical_feature] = dataframe[numerical_feature].replace(\"\", np.nan)\n",
    "    return dataframe\n",
    "\n",
    "\n",
    "def casting_categorical(dataframe, categorical_feature):\n",
    "    \"\"\"Cast features to the correct type.\"\"\"\n",
    "    dataframe[categorical_feature] = dataframe[categorical_feature].astype(\"object\")\n",
    "    return dataframe\n",
    "\n",
    "\n",
    "def change_no_service_to_no(dataframe):\n",
    "    for col in dataframe.columns:\n",
    "        if dataframe[col].dtype == \"object\":\n",
    "            dataframe[col] = dataframe[col].replace(\"No phone service\", \"No\")\n",
    "            dataframe[col] = dataframe[col].replace(\"No internet service\", \"No\")\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# apply casting_numerical function to X_train and X_test simultaneously\n",
    "X_train, X_test = map(\n",
    "    lambda dataframe: casting_numerical(dataframe, \"TotalCharges\"),\n",
    "    [X_train, X_test],\n",
    ")\n",
    "\n",
    "X_train, X_test = map(\n",
    "    lambda dataframe: casting_categorical(dataframe, \"SeniorCitizen\"),\n",
    "    [X_train, X_test],\n",
    ")\n",
    "\n",
    "X_train, X_test = map(\n",
    "    lambda dataframe: change_no_service_to_no(dataframe),\n",
    "    [X_train, X_test],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# dropna from X_train and X_test simultaneously\n",
    "X_train, X_test = map(lambda dataframe: dataframe.dropna(), [X_train, X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "y_train = X_train[\"Churn\"]\n",
    "X_train = X_train.drop(\"Churn\", axis=1)\n",
    "\n",
    "y_test = X_test[\"Churn\"]\n",
    "X_test = X_test.drop(\"Churn\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "preprocessor = Pipeline(\n",
    "    [\n",
    "        (\"drop_vars\", DropFeatures([\"customerID\"])),\n",
    "        (\n",
    "            \"tenure_combine\",\n",
    "            CombineWithReferenceFeature(\n",
    "                variables_to_combine=[\"MonthlyCharges\", \"TotalCharges\"],\n",
    "                reference_variables=[\"tenure\"],\n",
    "                operations=[\"div\"],\n",
    "                new_variables_names=[\"tenureMonthlyRate\", \"tenureTotalRate\"],\n",
    "            ),\n",
    "        ),\n",
    "        (\n",
    "            \"totalcharges_combine\",\n",
    "            CombineWithReferenceFeature(\n",
    "                variables_to_combine=[\"TotalCharges\"],\n",
    "                reference_variables=[\"MonthlyCharges\"],\n",
    "                operations=[\"div\"],\n",
    "                new_variables_names=[\"RateCharge\"],\n",
    "            ),\n",
    "        ),\n",
    "        (\n",
    "            \"preprocessor\",\n",
    "            ColumnTransformer(\n",
    "                [\n",
    "                    (\n",
    "                        \"num\",\n",
    "                        make_pipeline(\n",
    "                            SimpleImputer(strategy=\"median\"),\n",
    "                        ),\n",
    "                        make_column_selector(dtype_include=np.number),\n",
    "                    ),\n",
    "                    (\n",
    "                        \"cat\",\n",
    "                        make_pipeline(\n",
    "                            SimpleImputer(strategy=\"most_frequent\"),\n",
    "                            TargetEncoder(),\n",
    "                        ),\n",
    "                        make_column_selector(dtype_include=[\"object\"]),\n",
    "                    ),\n",
    "                ],\n",
    "            ),\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a function to optimize the hyperparameters\n",
    "def objective(trial):\n",
    "    \"\"\"Objective function for Gradient Boosting Hyperparameter Optimization.\"\"\"\n",
    "    params = {\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 1000, 100),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-3, 1.0, log=True),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 9),\n",
    "        \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 2, 25),\n",
    "        \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 1, 25),\n",
    "        # \"max_features\": trial.suggest_categorical(\"max_features\", [\"auto\", \"sqrt\"]),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.1, 1.0),\n",
    "        \"random_state\": 42,\n",
    "    }\n",
    "\n",
    "    pipeline = Pipeline(\n",
    "        [\n",
    "            (\"preprocessor\", preprocessor),\n",
    "            (\"model\", GradientBoostingClassifier(**params)),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=42)\n",
    "\n",
    "    return np.mean(\n",
    "        cross_val_score(\n",
    "            pipeline,\n",
    "            X_train,\n",
    "            y_train,\n",
    "            cv=cv,\n",
    "            scoring=\"roc_auc\",\n",
    "            n_jobs=-1,\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "optuna.visualization.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# train the model with the best hyperparameters\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\n",
    "            \"model\",\n",
    "            GradientBoostingClassifier(\n",
    "                n_estimators=700,\n",
    "                learning_rate=0.0033570,\n",
    "                max_depth=5,\n",
    "                min_samples_split=6,\n",
    "                min_samples_leaf=21,\n",
    "                subsample=0.65,\n",
    "                random_state=42,\n",
    "            ),\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=42)\n",
    "scores = cross_val_score(\n",
    "    pipeline, X_train, y_train, scoring=\"roc_auc\", cv=cv, n_jobs=-1\n",
    ")\n",
    "print(\"Mean ROC AUC: %.3f\" % np.mean(scores), \"Std ROC AUC: %.3f\" % np.std(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = learning_curve(\n",
    "    pipeline, X_train, y_train, cv=cv, scoring=\"roc_auc\", n_jobs=-1\n",
    ")\n",
    "train_sizes, train_scores, test_scores = results[:3]\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.title(\"Learning Curve\")\n",
    "plt.xlabel(\"Training examples\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.grid()\n",
    "plt.fill_between(\n",
    "    train_sizes,\n",
    "    train_scores_mean - train_scores_std,\n",
    "    train_scores_mean + train_scores_std,\n",
    "    alpha=0.1,\n",
    "    color=\"r\",\n",
    ")\n",
    "plt.fill_between(\n",
    "    train_sizes,\n",
    "    test_scores_mean - test_scores_std,\n",
    "    test_scores_mean + test_scores_std,\n",
    "    alpha=0.1,\n",
    "    color=\"g\",\n",
    ")\n",
    "plt.plot(train_sizes, train_scores_mean, \"o-\", color=\"r\", label=\"Training score\")\n",
    "plt.plot(train_sizes, test_scores_mean, \"o-\", color=\"g\", label=\"Cross-validation score\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('.churnenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "48e938956b524bacc322bf102c9096bef6abd5ac7dd1f53fb6de73f073d72769"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
